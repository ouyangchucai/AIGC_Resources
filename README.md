# AIGC_Resources
Gather AIGC most useful tools, materials, publications and reports

<h2> Foundation Papers </h2>

<table>
  <thead>
    <tr>
      <th>Title</th>
      <th>Model</th>
      <th>Publication Date</th>
      <th>Code</th>
      <th>Organization</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank"><b>Attention Is All You Need</b></a></td>
      <td>Transformer</td>
      <td>Dec 2017</td>
      <td></td>
      <td>Google</td>
    </tr>
    <tr>
      <td><a href="https://arxiv.org/pdf/2108.07258.pdf" target="_blank"><b>Improving Language Understanding by Generative Pre-Training</b></a></td>
      <td>GPT</td>
      <td>Jun 2018</td>
      <td></td>
      <td>OpenAI</td>
    </tr>
    <tr>
      <td><a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank"><b>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</b></a></td>
      <td>Bert</td>
      <td>May 2019</td>
      <td></td>
      <td>Google</td>
    </tr>
    <tr>
      <td><a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank"><b>On the Opportunities and Risks of Foundation Models</b></a></td>
      <td></td>
      <td>Jul 2022</td>
      <td></td>
      <td>Center for Research on Foundation Models (CRFM) & Stanford Institute for Human-Centered Artificial Intelligence (HAI)</td>
    </tr>
    <tr>
      <td><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf" target="_blank"><b>Language Models are Unsupervised Multitask Learners</b></a></td>
      <td>GPT-2</td>
      <td>Dec 2020</td>
      <td><a href="https://github.com/openai/gpt-2" target="_blank">Code</a></td>
      <td>OpenAI</td>
    </tr>
    <tr>
      <td><a href="https://arxiv.org/pdf/2103.00020.pdf" target="_blank"><b>Learning Transferable Visual Models From Natural Language Supervision</b></a></td>
      <td>CLIP</td>
      <td>Feb 2021</td>
      <td><a href="https://github.com/openai/CLIP" target="_blank">Code</a></td>
      <td>OpenAI</td>
    </tr>
    <tr>
      <td><a href="https://arxiv.org/pdf/2107.03374.pdf" target="_blank"><b>Evaluating Large Language Models Trained on Code</b></a></td>
      <td>Codex</td>
      <td>Jul 2021</td>
      <td></td>
      <td>OpenAI</td>
    </tr>
    <tr>
      <td><a href="https://arxiv.org/pdf/2203.07814.pdf" target="_blank"><b>Competition-Level Code Generation with AlphaCode</b></a></td>
      <td>AlphaCode</td>
      <td>Feb 2022</td>
      <td></td>
      <td>DeepMind</td>
    </tr>
    <tr>
      <td><a href="https://arxiv.org/pdf/2203.13474.pdf" target="_blank"><b>Codegen: an open large language model for code with multi-turn program synthesis</b></a></td>
      <td>CodeGen</td>
      <td>March 2022</td>
      <td><a href="https://github.com/salesforce/CodeGen" target="_blank">Code</a></td>
      <td>Salesforce</td>
    </tr>
  </tbody>
</table>

<h2> Recent Papers </h2>
  <table>
    <tr>
      <th>Title</th>
      <th>Short Name</th>
      <th>Date</th>
      <th>Institution</th>
      <th>Code (if available)</th>
    </tr>
    <tr>
      <td><a href="https://arxiv.org/pdf/2203.02155.pdf" target="_blank"> Training language models to follow instructions with human feedback </a></td>
      <td>Instruct GPT</td>
      <td>March 2022</td>
      <td>OpenAI</td>
      <td></td>
    </tr>
    <tr>
      <td><a href="https://arxiv.org/pdf/2112.10752.pdf" target="_blank"> High-Resolution Image Synthesis with Latent Diffusion Models </a></td>
      <td>Stable Diffusion</td>
      <td>April 2022</td>
      <td>Heidelberg University & Runway</td>
      <td></td>
    </tr>
    <tr>
      <td><a href="https://cdn.openai.com/papers/dall-e-2.pdf" target="_blank"> Hierarchical Text-Conditional Image Generation with CLIP Latents </a></td>
      <td>Dalle 2</td>
      <td>April 2022</td>
      <td>OpenAI</td>
      <td></td>
    </tr>
    <tr>
      <td><a href="https://arxiv.org/pdf/2204.05862.pdf" target="_blank"> Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback </a></td>
      <td>RLHF</td>
      <td>Jun 2022</td>
      <td>Anthropic</td>
      <td></td>
    </tr>
    <tr>
      <td><a href="https://arxiv.org/pdf/2005.14165.pdf" target="_blank"> Language Models are Few-Shot Learners </a></td>
      <td>GPT-3</td>
      <td>Jun 2022</td>
      <td>OpenAI</td>
      <td></td>
    </tr>
    <tr>
  <td><a href="https://arxiv.org/pdf/2112.09332.pdf" target="_blank">WebGPT: Browser-assisted question-answering with human feedback</a></td>
  <td>WebGPT</td>
  <td>Jun 2022</td>
  <td>OpenAI</td>
  <td></td>
</tr>
<tr>
  <td><a href="https://cdn.openai.com/papers/whisper.pdf" target="_blank">Robust Speech Recognition via Large-Scale Weak Supervision</a></td>
  <td>Whisper</td>
  <td>Sep 2022</td>
  <td>OpenAI</td>
  <td><a href="https://github.com/openai/whisper" target="_blank">Code</a></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2302.13971.pdf" target="_blank">LLaMA: Open and Efficient Foundation Language Models</a></td>
  <td>LLaMA</td>
  <td>Feb 2023</td>
  <td>Meta</td>
  <td></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2303.04671.pdf" target="_blank">Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models</a></td>
  <td>Visual ChatGPT</td>
  <td>March 2023</td>
  <td>Microsoft</td>
  <td><a href="https://github.com/microsoft/visual-chatgpt" target="_blank">Code</a></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2303.01469.pdf" target="_blank">Consistency Models</a></td>
  <td></td>
  <td>March 2023</td>
  <td>OpenAI</td>
  <td><a href="https://github.com/openai/consistency_models" target="_blank">Code</a></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2302.14045.pdf" target="_blank">Language Is Not All You Need: Aligning Perception with Language Models</a></td>
  <td>Aligning</td>
  <td>March 2023</td>
  <td>Microsoft</td>
  <td></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2303.08774.pdf" target="_blank">GPT-4 Technical Report</a></td>
  <td>GPT-4</td>
  <td>March 2023</td>
  <td>OpenAI</td>
  <td></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2303.17580.pdf" target="_blank">BloombergGPT: A Large Language Model for Finance</a></td>
  <td>BloombergGPT</td>
  <td>March 2023</td>
  <td>Bloomberg</td>
  <td></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2303.17580.pdf" target="_blank">HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face</a></td>
  <td>HuggingGPT</td>
  <td>April 2023</td>
  <td>Microsoft</td>
  <td><a href="https://github.com/microsoft/JARVIS" target="_blank">Code</a></td>
</tr>
<tr>
  <td><a href="https://ai.facebook.com/research/publications/segment-anything/" target="_blank">Segment Anything</a></td>
  <td>SAM</td>
  <td>April 2023</td>
  <td>Meta</td>
  <td><a href="https://github.com/facebookresearch/segment-anything" target="_blank">Code</a></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2304.03277.pdf" target="_blank">Instruction Tuning with GPT-4</a></td>
  <td></td>
  <td>April 2023</td>
  <td>Stanford & Google</td>
  <td><a href="https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM" target="_blank">Code</a></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2304.03442.pdf" target="_blank">Generative Agents: Interactive Simulacra of Human Behavior</a></td>
  <td></td>
  <td>April 2023</td>
  <td>Microsoft</td>
  <td></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2304.07193.pdf" target="_blank">DINOv2: Learning Robust Visual Features without Supervision</a></td>
  <td>DINOv2</td>
  <td>April 2023</td>
  <td>Meta</td>
  <td></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2305.02463v1.pdf" target="_blank">Shap·E: Generating Conditional 3D Implicit Functions</a></td>
  <td>Shap·E</td>
  <td>May 2023</td>
  <td>OpenAI</td>
  <td><a href="https://github.com/openai/shap-e" target="_blank">Code</a></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2305.05665.pdf" target="_blank">IMAGEBIND: One Embedding Space To Bind Them All</a></td>
  <td>IMAGEBIND</td>
  <td>May 2023</td>
  <td>Meta</td>
  <td></td>
</tr>
<tr>
  <td><a href="https://arxiv.org/pdf/2305.10973.pdf" target="_blank">Drag Your GAN: Interactive Point-based Manipulation on the
Generative Image Manifold</a></td>
  <td>DragGAN</td>
  <td>May 2023</td>
  <td>Many</td>
  <td><a href="https://vcai.mpi-inf.mpg.de/projects/DragGAN/" target="_blank">Code</a></td>
</tr>
  </table>


<h2> Important Reports </h2>

<table>
  <tr>
    <th>Report</th>
    <th>Link</th>
    <th>Institution</th>
  </tr>
  <tr>
    <td>Stanford AI index Report 2023</td>
    <td><a href="https://aiindex.stanford.edu/report/" target="_blank">Link</a></td>
    <td>Stanford</td>
  </tr>
  <tr>
    <td>Sparks of Artificial General Intelligence: Early experiments with GPT-4</td>
    <td><a href="https://arxiv.org/pdf/2303.12712.pdf" target="_blank">Link</a></td>
    <td>Microsoft</td>
  </tr>
  <tr>
    <td>A Survey of Large Language Models</td>
    <td><a href="https://arxiv.org/pdf/2303.18223.pdf" target="_blank">Link</a></td>
    <td>Renmin University, China & University of Montreal, Canada</td>
  </tr>
  <tr>
    <td>Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</td>
    <td><a href="https://arxiv.org/pdf/2304.13712v2.pdf" target="_blank">Link</a></td>
    <td>Amazon & many others</td>
  </tr>
  <tr>
    <td>A Cookbook of Self-Supervised Learning</td>
    <td><a href="https://arxiv.org/pdf/2304.12210.pdf" target="_blank">Link</a></td>
    <td>Meta & many others</td>
  </tr>
</table>



<h2> Important Projects</h2>

<b>  <a href="https://www.midjourney.com/" target="_blank">  MidJourney </a>    </b>  

<b>  <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html" target="_blank">  Alpaca  </a>    </b>    <a href="https://github.com/tatsu-lab/stanford_alpaca" target="_blank"> Open Source Code </a>  Stanford    March 2023

<b>  <a href="https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html" target="_blank">  Dolly  </a>    </b>    <a href="https://github.com/databrickslabs/dolly" target="_blank"> Open Source Code </a>  Databricks     March 2023   Note: OK to use commercially 

<b>  <a href="https://vicuna.lmsys.org/" target="_blank">  Vicuna  </a>    </b>    <a href="https://github.com/lm-sys/FastChat" target="_blank"> Open Source Code </a>   UC Berkeley, CMU, Stanford, and UC San Diego     March 2023
 
<b>  <a href="https://www.chatpdf.com/" target="_blank">  ChatPDF  </a>  </b>   March 2023

<b>  <a href="https://bard.google.com/" target="_blank">  Bard  </a>    </b>   Google   March 2023

<b>  <a href="https://github.com/hwchase17/langchain" target="_blank">  Langchain </a>    </b>   Community Effort   March 2023

<b>  <a href="https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/" target="_blank">  Microsoft 365 Copilot  </a>    </b>   Microsoft   March 2023

<b>  <a href="https://github.com/Torantulino/Auto-GPT" target="_blank">  AutoGPT </a>    </b>   Community Effort  April 2023

<b>  <a href="https://github.com/IDEA-Research/Grounded-Segment-Anything" target="_blank">  Grounded SAM </a>    </b>   IDEA  April 2023

<b>  <a href="https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-chat" target="_blank">  DeepSpeed Chat </a>    </b>   Microsoft  April 2023

<b>  <a href="https://github.com/reworkd/AgentGPT" target="_blank">  AgentGPT </a>    </b>   Community Effort  April 2023

<b>  <a href="https://minigpt-4.github.io/" target="_blank">  MiniGPT </a>    </b>   King Abdullah University of Science and Technology  April 2023

<b>  <a href="https://github.com/deep-floyd/IF" target="_blank">  DeepFloyd IF </a>    </b>  Stability.ai April 2023

<b>  <a href="https://github.com/openlm-research/open_llama" target="_blank">  Open Llama </a>    </b>  Berkeley  May 2023

<b>  <a href="https://github.com/svc-develop-team/so-vits-svc" target="_blank">  SoftVC VITS Singing Voice Conversion </a>    </b>  Community  May 2023

<h2> AIGC Courses </h2>

<b>  <a href="https://www.cs.princeton.edu/courses/archive/fall22/cos597G/" target="_blank">  COS597G Understanding Large Language Models  </a>    </b>   Princeton 2022

<b>  <a href="https://stanford-cs324.github.io/winter2022/" target="_blank">  CS324 Large Language Models  </a>    </b>   Stanford  2023



<h2> Very Useful Source Code </h2>

<b>  <a href="https://github.com/openai/openai-cookbook/" target="_blank">  OpenAI Cookbook  </a>    </b>  
<b>  <a href="https://gpt-index.readthedocs.io/en/latest/" target="_blank">  Llama Index </a>    </b>  
 

